{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_JEBd7eeh9S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"Tweets_Data.csv\",encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "q6jSsD8Vf8zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.iloc[:,1:]\n",
        "data.head()"
      ],
      "metadata": {
        "id": "QPpclXS_f82f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "hgZsL5osf84v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "7Ev5ePMBf86_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re #regular expression\n",
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = re.sub(\"[0-9\" \"]+\",\" \",text)\n",
        "    text = re.sub('[‘’“”…]', '', text)\n",
        "    return text\n",
        "\n",
        "clean = lambda x: clean_text(x)\n",
        "data['Text'] = data.Text.apply(clean)\n",
        "data.Text\n",
        "data_df = pd.DataFrame(data)\n",
        "data_df"
      ],
      "metadata": {
        "id": "Dg72UZWof89R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word frequency\n",
        "freq = pd.Series(' '.join(data['Text']).split()).value_counts()[:20] # for top 20\n",
        "freq"
      ],
      "metadata": {
        "id": "ueRGhjtAgKk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop = pd.read_csv('stop.txt')\n",
        "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
      ],
      "metadata": {
        "id": "0Tg8Br9qgO_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word frequency after removal of stopwords\n",
        "freq_Sw = pd.Series(' '.join(data['Text']).split()).value_counts()[:20] # for top 20\n",
        "freq_Sw"
      ],
      "metadata": {
        "id": "5Sxd0lMDgQhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1q6vQD5zaRYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectoriser tells the frequency of a word.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "vectorizer = CountVectorizer(min_df = 1, max_df = 0.9)\n",
        "X = vectorizer.fit_transform(data[\"Text\"])\n",
        "word_freq_df = pd.DataFrame({'term': vectorizer.get_feature_names_out(), 'occurrences':np.asarray(X.sum(axis=0)).ravel().tolist()})\n",
        "word_freq_df['frequency'] = word_freq_df['occurrences']/np.sum(word_freq_df['occurrences'])\n",
        "#print(word_freq_df.sort('occurrences',ascending = False).head())"
      ],
      "metadata": {
        "id": "YzFn57LFgQmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq_df.head(30)"
      ],
      "metadata": {
        "id": "q9qIqwJZggkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TFIDF - Term frequency inverse Document Frequency\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000, max_df = 0.5, smooth_idf=True) #keep top 1000 words\n",
        "doc_vec = vectorizer.fit_transform(data[\"Text\"])\n",
        "names_features = vectorizer.get_feature_names_out()\n",
        "dense = doc_vec.todense()\n",
        "denselist = dense.tolist()\n",
        "df = pd.DataFrame(denselist, columns = names_features)"
      ],
      "metadata": {
        "id": "t4yft0gdggmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "eZEMM0vxggpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bi-gram\n",
        "def get_top_n2_words(corpus, n=None):\n",
        "    vec1 = CountVectorizer(ngram_range=(2,2),  #for tri-gram, put ngram_range=(3,3)\n",
        "            max_features=2000).fit(corpus)\n",
        "    bag_of_words = vec1.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in\n",
        "                  vec1.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1],\n",
        "                reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "metadata": {
        "id": "QOtQKCjlgnpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top2_words = get_top_n2_words(data[\"Text\"], n=200) #top 200\n",
        "top2_df = pd.DataFrame(top2_words)\n",
        "top2_df.columns=[\"Bi-gram\", \"Freq\"]\n",
        "top2_df.head()"
      ],
      "metadata": {
        "id": "qUZywZE_gnsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top2_df"
      ],
      "metadata": {
        "id": "uX5VHIj5V7jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tri-gram\n",
        "def get_top_n3_words(corpus, n=None):\n",
        "    vec1 = CountVectorizer(ngram_range=(3,3),\n",
        "           max_features=2000).fit(corpus)\n",
        "    bag_of_words = vec1.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in\n",
        "                  vec1.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1],\n",
        "                reverse=True)\n",
        "    return words_freq[:n]\n",
        "top3_words = get_top_n3_words(data[\"Text\"], n=200)\n",
        "top3_df = pd.DataFrame(top3_words)\n",
        "top3_df.columns=[\"Tri-gram\", \"Freq\"]"
      ],
      "metadata": {
        "id": "8kGd8mIFgv5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top3_df"
      ],
      "metadata": {
        "id": "qJB-0_qMgv7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment analysis\n",
        "afinn = pd.read_csv('Afinn.csv', sep=',', encoding='latin-1')\n",
        "afinn.shape\n",
        "(2477, 2)\n",
        "afinn.head()"
      ],
      "metadata": {
        "id": "s4xHOTQIg5Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "\n",
        "def take(n, iterable):\n",
        "    \"Return first n items of the iterable as a list\"\n",
        "    return list(islice(iterable, n))\n",
        "affinity_scores = afinn.set_index('word')['value'].to_dict()\n",
        "take(20, affinity_scores.items())"
      ],
      "metadata": {
        "id": "YO6cwcbyg5VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "#Custom function :score each word in a sentence in lemmatised form,\n",
        "#but calculate the score for the whole original sentence.\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "sentiment_lexicon = affinity_scores\n",
        "\n",
        "def calculate_sentiment(data: str = None) -> float:\n",
        "    sent_score = 0\n",
        "    if data:\n",
        "        sentence = nlp(data)\n",
        "        for word in sentence:\n",
        "            sent_score += sentiment_lexicon.get(word.lemma_, 0)\n",
        "    return sent_score\n",
        "# test that it works\n",
        "calculate_sentiment(data = 'very sad')\n",
        "-2\n",
        "data_df['sentiment_value'] = data_df['Text'].apply(calculate_sentiment)\n",
        "data_df"
      ],
      "metadata": {
        "id": "fKFMgHxOg5W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many words are in the Text?\n",
        "data_df['word_count'] = data_df['Text'].str.split().apply(len)\n",
        "data_df['word_count'].head(10)"
      ],
      "metadata": {
        "id": "gyMp5BhJhWnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.sort_values(by='sentiment_value').tail(10)"
      ],
      "metadata": {
        "id": "uCjGTZDWhWq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment score of the whole review\n",
        "data_df['sentiment_value'].describe()"
      ],
      "metadata": {
        "id": "RqEnuV55hWtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment score of the negative reviews\n",
        "data_df[data_df['sentiment_value']<0].head(10)"
      ],
      "metadata": {
        "id": "sZKyd1J7hWvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment score of the positive reviews\n",
        "data_df[data_df['sentiment_value']>0].head(10)"
      ],
      "metadata": {
        "id": "XIlUKYDmhez_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df[data_df['sentiment_value']>10].head(10)"
      ],
      "metadata": {
        "id": "qLhnU2qahe2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "id": "lZIkosgVhpaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for value in data_df[\"sentiment_value\"]:\n",
        "    if value < 0 :\n",
        "        result.append(\"Negative\")\n",
        "    elif value == 0 :\n",
        "        result.append(\"Neutral\")\n",
        "    else :\n",
        "        result.append(\"Positive\")\n",
        "\n",
        "data_df[\"sentiment_value\"] = result\n",
        "print(data_df)"
      ],
      "metadata": {
        "id": "w_tx7KThhpcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "id": "ZJ23_UyKhwxv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}